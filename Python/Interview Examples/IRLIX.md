- K8s https://s3rius.blog/start-with-k8s
- КОРУТИНЫ https://pavel-karateev.gitbook.io/intermediate-python/struktury-dannykh/coroutines
- GIL https://www.youtube.com/watch?v=AWX4JnAnjBE
- Сложность алгоритмов https://habr.com/ru/post/188010/

## Python:

- Типы данных
  - int, float, str, bool, list, set, frozenset, dict, tuple, bytes, bytearray, complex
  - Изменяемые:
    - list, dict, set, byte array
  - Неизменяемые:
    - int, float, complex, string, tuple, frozenset (неизменяемая версия set), bytes
- Хэш функции
  - Хэш-функция - это функция, которая принимает на вход какие-либо данные (например, строки) и возвращает число по некоторому заданному алгоритму.
  - Назначением хэш-функций является возможность помещения некоторого элемента (например, строки) в хэш-таблицу, на основе которых реализованы, например, словари и множества в Python.
- на основании какой структуры данных реализованный Словари?
  - Hash таблицы. Ключами могут быть только Immutable типы данных, чтобы можно было взять hash.
  - Сейчас в питоне сохраняется последовательность данных в словаре, (с Python 3.9)
- Коллизия что такое?
  - hash берущийся от двух разных значений - идентичен.
  - При поиске элемента, если находится два идентичных Hash'a, то сравниваются значения. Если не совпало, то берется следующий.
- Методы решения коллизий(открытой адресации и цепочек) [link](http://genius.pstu.ru/file.php/1/pupils_works_2017/MuhinaAlisa.pdf)
  - если хэш функция идеальна, то коллизии не будет
  - метод адресации открытой, когда идем дальше и пытаемся найти пустой слот для записи элемента. ! иногда придется пройти циклически начиная с самого первого элемента и до того что вызвало коллизию. (будут проблемы с вставкой, так как много мест будет занято, а скучковавшиеся элементы будут превращаться в некий кластер)
  - метод цепочек - В позиции номер i хранится указатель на голову списка тех элементов, у которых хеш-значение ключа равно i; если таких элементов в множестве нет, в позиции i записан NULL.
- Декораторы
  - Вносит дополнительную функциональность, не изменяя основную логику
  - Реализовать можно через функцию или класс `__call__` и `__init__` переопределить:)
- Генераторы (yield)
  - Генератор — это объект, который сразу при создании не вычисляет значения всех своих элементов
  - Он хранит в памяти только последний вычисленный элемент, правило перехода к следующему и условие, при котором выполнение прерывается
  - Вычисление следующего значения происходит лишь при выполнении метода next(). Предыдущее значение при этом теряется
- Итераторы
  - обьект, имеющий метод `__next__`
- Чем отличается Генератор от Итератора?
  - генератор в отличие от итератора не хранит все элементы последовательности в памяти.
  - Генератор - частный случай итератора (но не наоборот)
- Корутины
  - Корутины похожи на генераторы за исключением нескольких отличий, основные из которых:
    - генераторы возвращают данные
    - корутины потребляют данные
  - ```python
    def function():
    while True:
        line = (yield)
        print(line)
    ```

- GIL
  - Проблемы при параллельщине это GIL. Работает он стороне C, защищает только инструкции интерпретатора. Обьекты в питоне самом можно защитить через threadingLock Queue Event и тд. GIL Предотвращает проблемы с работой двух потоков и обращениями к одной ячейке памяти. По сути это глобальный мьютекс. Он позволяет не беспокоится за эти проблемы.
  - Именно поэтому несколько потоков одновременно выполняться не могут GIL контролирует запуск потоков, не давая другим запуститься пока какой то работает. Еще мы не умеем контролировать выключение потока , именно поэтому разработчики сделали GIL неким менеджером, что контролирует именно запуск потоков новых, пока один работает - другие спят.
  - Раньше потоки работали по тикам, и эти тики могли длиться слишком долго, что позволяло в одном тике итерироваться по n объектам массива. Эту проблему решили, создав стратегию - при которой 5 мс отводится на работу потока, затем он переключается на другой
  - Вообще мультипроцессность решает проблемы CPU bound . Проблемы мощности и способности вычислений, а многопоточность - IObound. Пока один поток ждет ответ от бд - второй работает.
  - Многие программисты используют нетривиальные вещи. Например RPython Ipython, исключая работу с GIL, так как Гил работает именно на стороне C, а не Python.
  - Есть еще проблема у мультипроцессности - дележка какими то данными. Это решается через Kafka какую нибудь или через сокеты. Идеальное решение для этого есть в Go - channels. Нужно это, чтобы запихать данные в канал и поделиться чем то с другими процессами.
  - У потоков все проще. Они делят память внутри одного процесса, у них общение и дележка данными совершенно иная и намного проще процессов.
  - А асинхронщина обычный event loop. Без менеджера переключений , это приводит к тому что может произойти переключение не на столь важные вещи. Плюс высока проблема работы под нагрузкой, так как время ожидания выполнения и переключения между одним действием и другим начинает возрастать. Поэтому не всегда асинхронный код работает быстрее синхронного.
- Асинхронность event loop
  - 1 процесс 1 ядро
  - потоки выполняются последовательно ( хотя кажется что одновременно )
  - OS когда работает с потоками, она переключает их в случайное время
- Теорию по асинхронности и asyncio.
  - ``asyncio`` — это библиотека для написания конкурентного кода с использованием синтаксиса async/await.
  - она подходит для связанного с вводом-выводом и высокоуровневого структурированного сетевого кода.
  - основная единица - корутины (сопрограммы), над которыми можно управлять выполнением
  - можно управлять под процессами
  - распределять задачи через очередь
  - выполнение сетевого ввода-вывода
  - надо синхронизировать - с помощью примитивов (мьютексов)
  - https://digitology.tech/docs/python_3/library/asyncio.html


## Django
- queryset
  - это абстракция над Raw SQL.
  - ленивые - процесс создания QuerySet не связан с какими-либо действиями с базой данных.
  - ленивый. Его можно создавать, фильтровать и вообще передавать без фактического обращения к базе данных.
  - Никаких запросов к бд не будет, пока не сделать что то для его вычисления.
    - Итерация по нему
    - Асинхронная итерация
    - обернуть в list()
    - pickle
    - caching
    - Срезы
    - Обернуть в len()
    - Обернуть в repr()
- когда именно совершаются запросы к бд в джанге
-
ПОДРОБНЕЕ (ВНЕШНИЕ И ПЕРВИЧНЫЕ КЛЮЧИ ЧЕ ТО ТАМ)
По сути будут производиться Join'ы, засчет которых ORM сделает меньше запросов к БД.
- select_related
  - `select_related` для `ForeignKey`, `OneToOne` (когда обьект один). Позволяет нам точно указать Django, какие связанные модели мы хотим, чтобы он мог заранее выполнить JOINs
- prefetch_related
  - `prefetch_related` для `ManyToMany`.
- Prefetch
  - В некоторых сценариях простого синтаксиса `prefetch_related` недостаточно, чтобы Django не выполнял дополнительные запросы. Для большего контроля предварительной выборки вы можете использовать объект предварительной выборки `Prefetch`
- Оптимизация запросов бд
  - кэширование id, для получения их для FK (в джанге вроде как поумолчанию)
  - select_related, prefetch_related, Prefetch, чтобы получить все в 1 запросе (для prefetch_related - 2)
  - накидывание индексации (но тут аккуратно надо, а то много проблем повлечет за собой, например вставка)
  - кэширование постоянных запросов.
  - убирание ненужных полей из запроса (не select *, а перечисляем что нужно)
  - для просмотра запросов можно глянуть Explain
  - ``Entry.objects.all().iterator()`` итератор чтобы не грузить все обьекты в память при ``.all()``
  - aggregation
  - F
  - не сортировать результаты, если нет нужды
  - использование count() и exist() для проверки наличия и подсчета обьектов
  - ``bulk_create()`` для массового создания, но с ним надо быть аккуратней, сигналы некоторые не отсылаются при таком подходе.
  - ``values()``, ``values_list()`` для представления данных в виде массива
  - ``defer()``, ``only()`` если нам нужны определенные поля в queryset'е.

## БД
- индексация
  - ```sql
    Syntax:
    CREATE INDEX [index_name]
    ON [table_name] ([column_name])
    USING HASH(column_name); - можно и без USING и будет by default B-Tree.
    ```
- Какие бывают индексы, как работают, виды и отличия [link](https://tproger.ru/articles/indeksy-v-postgresql/)
  - Древовидные индексы. Все сбалансированные древовидные структуры имеют O(log n) сложность для поиска.
  - B-Tree (Сбалансированное дерево) - создается по-умолчанию. В большинстве случаев его достаточно.
  - Хэш-индекс - поддерживает только оператор сравнения. Сложность поиска константная, но имеет много ограничений.
  - GiST (обобщенное дерево поиска) - применяется для индексации текстовых данных и полнотекстового поиска. Занимает меньше места чем GIN, но может быть менее эффективен за счет доп проверок.
  - GIN (обобщенный обратный) - Он работает обычно с массивами или наборами значений, jsonb. При этом индексируются не сами значения, а отдельные элементы; Можно сделать полнотекстовый поиск, причем более сложный чем в GIST. (с регулярными выражениями).
  - SP-GiST (GiST c двоичным разбиением пространства) - используется с наборами данных. (например телефонные номера)
  - RUM
  - R-tree
  - K-tree и другие.....
- отличие операторов Where от Having?
  - WHERE сначала выбирает строки, а затем группирует их и вычисляет агрегатные функции (таким образом, она отбирает строки для вычисления агрегатов)
  - HAVING отбирает строки групп после группировки и вычисления агрегатных функций
  - WHERE не должно содержать агрегатных функций
  - HAVING, напротив, всегда содержит агрегатные функции
- Like
  - в отличие от `=`, которое выполняет точное сопоставление, Like сравнивает по некоему шаблону и примерно соответствие строки ему.
- Explain
  - показывает как запрос выглядит, помогает выявить узкие и потенциально медленные места.
- Acid
  - набор требований к транзакциям в системе. Атомарность, согласованность, изоляция, устойчивость.
  - Атомарность - никакая транзакция не будет зафиксирована в системе частично
  - Согласованность - каждая успешная транзакция по определению фиксирует только допустимые результаты
  - Изоляция - параллельные транзакции не должны оказывать влияние на результат другой транзакции
  - Устойчивость - если пользователь получил подтверждение от системы, что транзакция выполнена, он может быть уверен, что сделанные им изменения не будут отменены из-за какого-либо сбоя.
- Транзакции
  - это операции которые либо полностью завершены, либо если один из этапов упал - откатываются все предыдущие (либо операции все полностью не завершены).
- Уровни изоляции транзакций
  - Read uncommitted
    - решает Потерянное обновление
    - блокируем данные на запись и две параллельные транзакции - последовательно выполнятся
  - Read Committed
    - решает Грязное чтение
    - когда одна транзакция завершилась и изменила данные, а вторая транзакция все еще работает со старыми
    - можно блокировать изменяемые данные для читающих транзакций до завершения изменяющей транзакции
    - или можно хранить две версии параллельно изменяемых строк
    - - блокировка на запись работает до конца отдельной операции
  - Repeatable read
    - решает Неповторяющееся чтение
    - Уровень, при котором читающая транзакция «не видит» изменения данных, которые были ею ранее прочитаны. При этом никакая другая транзакция не может изменять данные, читаемые текущей транзакцией, пока та не окончена.
    - блокировка на запись работает до конца транзакции, а не отдельной операции
  - Serializable
    - решает Фантомное чтение
    - Самый высокий уровень изолированности
    - Транзакции полностью изолируются друг от друга, каждая выполняется так, как будто параллельных транзакций не существует.
    - обеспечивается блокировкой и на запись, и на чтение любого блока данных, с которым мы работаем.
- Проблемы транзакций?
  - Потерянное обновление
    - Когда несколько транзакций что-то обновили в БД, но по итогам результат такой, будто отработала лишь часть транзакций.
    - полное отсутствие изоляции транзакций
  - Грязное чтение
    - Когда ваша транзакция может прочитать данные, которые были добавлены/изменены другой транзакцией, пока та ещё не вызвала COMMIT этих данных (ещё другая транзакция могла что-то удалить, тогда ваша транзакция перестанет это видеть).
  - Неповторяющееся чтение
    - Когда одинаковый запрос в одной транзакции может вернуть разные данные
  - Фантомное чтение
    - Когда: одинаковый запрос может вернуть НОВЫЕ строки, которые были закомичены из другой транзакции.
- Нормализация баз данных
  - есть 6 нормальных форм
  - это процесс организации данных в базе данных, включающий создание таблиц и установление отношений между ними в соответствии с правилами, которые обеспечивают защиту данных и делают базу данных более гибкой, устраняя избыточность и несогласованные зависимости.
- Методы оптимизации баз данных. [VIDEO](https://www.youtube.com/watch?v=9yWZ-LIsAII)
  - можно оптимизировать запросы, структуру бд, сам сервер.
  - кэширование в приложении, чтобы уменьшить количество запросов к бд.
  - подзапросы
  - покрывающий индекс (или составной), возможно иногда стоит избавиться от индексов.
  - шардирование (шардинг)
  - CQRS
  - грамотная постановка уровня изоляции, так как блокировки, хоть и полезны, но тормозят работу бд.
  - оптимизация на уровне приложения (Уменьшение времени блокировок).
  - если надо оптимизировать удаление всех данных в таблице:
    - вместо Delete построчно в таблице, можно использовать Truncate
    - НО ОН не заботится об FK, и связных таблицах.
  - можно оптимизировать Limit со смещением заменив его на where limit (спорная херня)
    ````sql
    select * from movies order by title limit 100 offset 2000
    ->>
    select * from movies where title > 'naming' order by title limit 100
    ````
  - отдельно изощренные люди count оптимизируют... если надо сделать пагинацию или подсчет страниц.
    через подзапрос
    ````sql
    select count(*) from (select * from tags where name LIKE 'NAME%')
    ````
  - можно реализовать механизм отложенного запуска и системы накопления запросов, чтобы отправлять данные пачками а не по одному.

  - 1) заранее как можно сильнее фильтровать данные еще до момента соединения их с другими таблицами
  - 2) старайтесь как можно меньше по объему данных сортировать результирующий набор
  - 3) по возможности избегайте конструкции DISTINCT, LIKE '%...', OUTER JOIN особенно на больших данных
  - 4) если в выборке нужно лишь одно поле от соединяемой таблицы, то не соединяйте такую таблицу, а в самой выборке сделайте подзапрос
  - 5) при фильтрации, агрегации и выборке старайтесь учитывать имеющиеся индексы, чтобы оптимизатор мог ими воспользоваться
  - 6) старайтесь возвращать только те поля, которые действительно нужны, а не все поля из всех соединенных таблиц (не подходите унифицировано к коду в T-SQL, т к это очень плохой подход особенно с большими данными)
  - 7) при обновлении и удалении данных (если фильтр или агрегация построены не по кластерному индексу или помимо кластерного индекса есть и другие условия или агрегация), то не делайте операцию сразу по таблице, а сначала выберите удаляемые/изменяемые данные во временную таблицу (которая будет состоять из столбцов, которые входят в кластерный индекс, а также всех прочих необходимых полей для обновления) и уже после примените непосредственно удаление/обновление
  - 8) не перегружайте условия для соединения таблиц, а лучше вынесите часть условия в фильтр
  - 9) используйте разумно хинты к запросам

- Шардирование
  - По мере того, как данные в базе данных становятся все больше и больше, производительность запросов к одной таблице больше не может соответствовать бизнес-требованиям. Необходимо разделить таблицу на несколько небольших таблиц. Это может снизить нагрузку на запросы и повысить эффективность обработки.
  - Vertical partitioning — поколоночно. Например, есть гигантская таблица на пару миллиардов записей в 60 колонок. Вместо того, чтобы держать одну такую гигантскую таблицу, держим 60 не менее гигантских таблиц по 2 млрд записей — и это не поколоночная база, а вертикальное партиционирование (как пример терминологии).
  - Horizontal partitioning — режем построчно, может быть, внутри сервера.
- CQRS (Command and Query Responsibility Segregation)
  - CQRS — это стиль архитектуры, в котором операции чтения отделены от операций записи.
  - [link](https://docs.microsoft.com/ru-ru/azure/architecture/patterns/cqrs)
  - Более простые запросы. Сохраняя в базе данных для чтения материализованное представление данных, вы предотвратите использование приложением сложных соединений в запросах.
  - Независимое масштабирование. CQRS позволяет раздельно масштабировать рабочие нагрузки чтения и записи, снижая риск конфликтов блокировки.

## Tools
- Вопросы по redis rabitmq
- что такое redis?
  - Redis - быстрое key-value хранилище, развертываемое в ОЗУ. Оно периодически делает дампы на ЖД, но пока работает - использует именно ОЗУ.
  - часто используется для
    - кэширования
    - брокер-сообщений
    - для хранения быстрых данных и/или промежуточных данных
    - для хранения сессий
  - обеспечивает низкую задержку и высокую пропускную способность доступа к данным
- типы данных которые Redis поддерживает?
  - строки до 512мб
  - списки
  - множества (и сортированные)
  - хэш-таблицы
  - битовые массивы
  - потоки (очереди сообщений со структурой журналов данных)
  - пространственные данные (долгота и широта)
  - JSON
- какие бывают брокеры?
  - Полноценный сервера очередей это Kafka, RabbitMQ, они имеют свою бд под капотом.
  - Redis обычная база данных, над которой можно построить очередь без полноценной стратегии.
  - Брокеры нужны для периодических и отложенных задач
  - Выполняют код как бы асинхронно, не нагружая основную систему( допустим отправка сообщений или выгрузка/загрузка каких то данных)
- как выбирать брокер для проекта?
  - kafka - очень производительна (хранит пулл задач в журнале???)
  - redis более простой (хранит пулл задач в Оперативке)
  - в kafka, rabbitmq есть гарантия доставки сообщений. в Redis - нет. По сути Redis и не брокер то. В нем хранятся просто ключ значение. нет ни стратегии, ни гарантии. Используется для чего-то не важного. Зато запускается быстро - 1 строка в настройках джанги и все, а с Rabbitmq повозиться надо.
- примитивы celery (chain, groups).
  - только отложенные таски, переодичные использовал
  - shared task это декоратор, позволяющий создавать задачи без конкретного экземпляра приложения.
    ```python
      @shared_task
      def count_widgets():
          return Widget.objects.count()
    ```
  - task - декоратор требующий инстанс приложения
    ```python
      app = Celery('proj')

      @app.task(bind=True)
      def count_widgets(self):
          return Widget.objects.count()
    ```
  - chain - для последовательного выполнения задач. Каждая задача следует одна за другой, применяясь как (callback) обратный вызов предыдущей задачи.
    ```python
      >>> res = chain(add.s(2, 2), add.s(4))()
      >>> res.get()
      8
    ```
  - groups - для слияния двух групп задач в одну. Они корректно выполнятся одна за другой
    ```python
      >>> result = group(add.si(1, 2), add.si(1, 2)) | group(tsum.s(), tsum.s()).delay()
      >>> result.get()
      [6, 6]
    ```
- Для работы Celery и отложенных задач надо:
  - Producer: Your Django app
  - Message Broker: The Redis server
  - Consumer: Your Celery app
- **Pytest**
- **K8s**
  - **Container** - как и в докере например.
  - **Pod** - это логически связанные группы контейнеров. Это самая базовая еденица кубернетеса (от 1 до n контейнеров в 1м поде).
  - **Deployment** - нужен для описания механизмов создания ресурсов и подов. ДЛЯ СКЕЙЛИНГА
  - **Service** - это ресурс, с помощью которого поды могут общаться между собой. По сути это прокси сервер и балансировщик.
  - **Ingress** - это сервис описывающий куда пускать трафик, который поступает снаружи кластера.
  - **Namespace** - логические разделители уровня доступа. Разные неймспейсы под разные группы приложений.
  - **Secret** - сертификаты или какие-нибудь ключи.
  - **ConfigMap** - для хранения переменных среды.


## Архитектура
- **SOLID**
  - **Single Responsibility Principle (Принцип единственной обязанности)**. Один класс выполняет только одну работу
  - **Open-Closed Principle (Принцип открытости/закрытости)**. Программные сущности (классы, модули, функции) должно быть открыты для расширения, но не модификации.
  - **Liskov Substitution Principle (Принцип подстановки Лисков)**. Для любого класса клиент должен иметь возможность использовать любой подкласс базового класса, не замечая разницы между ними. Интерфейсы идентичны должны быть.
  - **Interface Segregation Principle (Принцип разделения интерфейсов)**. Клиенты не должны зависеть от интерфейсов, которые они не используют.
  - **Dependecy Inversion Principle (Принцип инверсии зависимостей)**. Зависимость должна быть от абстракций, а не от конкретики. Модули верхних уровней не должны зависеть от модулей нижних уровней. Классы и верхних, и нижних уровней должны зависеть от одних и тех же абстракций. Абстракции не должны зависеть от деталей. Детали должны зависеть от абстракций.

- KISS (keep it simple, stupid)
  - принцип проектирования, при котором простота системы декларируется в качестве основной цели или ценности.
- DRY (don’t repeat yourself)
  - доступ к конкретному функционалу должен быть доступен в одном месте, унифицирован и сгруппирован по какому-либо принципу, а не «разбросан» по системе в произвольных вариациях
- YAGNI (You aren't gonna need it)
  - возможности, которые не описаны в требованиях к системе, просто не должны реализовываться.
- ПАТТЕРНЫ ПРОЕКТИРОВАНИЯ (какие знаешь как и для чего применяются)
  - адаптер - позволяет объектам с несовместимыми интерфейсами работать вместе
  - синглтон - позволяет создать обьект, который будет в единственном экземпляре в системе.
  - декоратор - позволяет расширить уже существующую функциональность класса.
  - цепочка обязанностей - позволяет избежать привязку отправителя к получателю. Запрос идет по цепочке, пока его кто-то не обработает.
  - наблюдатель - позволяет нотифицировать все зависящие обьекты о каких-то изменениях.
  - фасад - определяет интерфейс для более высокого уровня системы, чтобы удобнее работать с более низкими
  - фабрика - Определяет интерфейс для создания объекта, но оставляет подклассам решение о том, какой класс инстанцировать.
  - ну и слышал об:
    - стратегия
    - строитель
    - мост
    - посетитель
    - и тд.

## FAST API
- это асинхронный фреймворк для построения АПИшек, основанный на типах. Производительность иногда достигает уровня Go.
- Fast api - dependency injection https://fastapi.tiangolo.com/tutorial/dependencies/
  - Функция не стартанет, пока параметры в Depends не будут готовы.
  - Depends типа обработчика такой прослойки, которая следит чтобы основная функция что-то возвращала. Вернула - пошло в параметр и основная логика запустилась.
  - нужна чтобы можно было Callable обьект запихать в параметр и чтоб он сработал перед запуском функции. вот это ИНЪЕКЦИЯ.
- events FastAPi https://fastapi.tiangolo.com/advanced/events/
  - @app.on_event("startup") - позволяет что то сделать перед запуском приложения. Инициализировать конфиги или подключения сделать каике то и тд.
  - @app.on_event("shutdown") - то же самое, только при остановке приложения. Оно остановилось - функция запустилась.
  - используют

* Теорию по асинхронности и asyncio.
* Чистый SQL.
* Методы оптимизации баз данных.
* Названия шаблонов проектирования (Как они строятся он знает, а названия путает).
* По джанго надо именно теоретическую часть подлатать. Так как запросы писать умеет, проблемы в них тоже нашёл сразу. А в теории просадка.
